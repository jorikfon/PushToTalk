import Foundation
import AVFoundation
import Accelerate
import PushToTalkCore

/// –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—Ç–ª–∞–¥–∫–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Voice Activity Detection
/// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .build/debug/VADTest <–ø—É—Ç—å_–∫_–∞—É–¥–∏–æ_—Ñ–∞–π–ª—É> [–ø–∞—Ä–∞–º–µ—Ç—Ä—ã]
@main
struct VADTest {
    static func main() async {
        print("üéôÔ∏è VAD Test Tool - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—á–∏\n")

        let args = CommandLine.arguments
        guard args.count >= 2 else {
            printUsage()
            return
        }

        let filePath = args[1]
        let url = URL(fileURLWithPath: filePath)

        guard FileManager.default.fileExists(atPath: filePath) else {
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: \(filePath)")
            return
        }

        print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: \(url.lastPathComponent)")

        do {
            // –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            let (audioSamples, sampleRate, channelCount, duration) = try await loadAudioFile(url)

            print("‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω:")
            print("   ‚Ä¢ Sample Rate: \(Int(sampleRate)) Hz")
            print("   ‚Ä¢ Channels: \(channelCount)")
            print("   ‚Ä¢ Duration: \(formatDuration(duration))")
            print("   ‚Ä¢ Samples: \(audioSamples.count)")
            print()

            // –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            printAudioStats(audioSamples)

            // –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã VAD
            print("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            print("üî¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ VAD\n")

            // 1. Default –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            testVADWithParameters(
                audioSamples: audioSamples,
                name: "Default (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)",
                parameters: .default
            )

            // 2. Low Quality –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            testVADWithParameters(
                audioSamples: audioSamples,
                name: "Low Quality (—Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–µ –∞—É–¥–∏–æ)",
                parameters: .lowQuality
            )

            // 3. High Quality –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            testVADWithParameters(
                audioSamples: audioSamples,
                name: "High Quality (—á–∏—Å—Ç–æ–µ –∞—É–¥–∏–æ)",
                parameters: .highQuality
            )

            // 4. Very Sensitive (–æ—á–µ–Ω—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π)
            let verySensitive = VADParameters(
                windowSize: 0.05,
                minSpeechDuration: 0.2,
                minSilenceDuration: 0.3,
                rmsThreshold: 0.005  // –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            )
            testVADWithParameters(
                audioSamples: audioSamples,
                name: "Very Sensitive (–æ—á–µ–Ω—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π)",
                parameters: verySensitive
            )

            // 5. Aggressive (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ)
            let aggressive = VADParameters(
                windowSize: 0.02,
                minSpeechDuration: 0.1,
                minSilenceDuration: 0.1,
                rmsThreshold: 0.01
            )
            testVADWithParameters(
                audioSamples: audioSamples,
                name: "Aggressive (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ)",
                parameters: aggressive
            )

            // 6. Conservative (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ - –¥–ª–∏–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã)
            let conservative = VADParameters(
                windowSize: 0.1,
                minSpeechDuration: 1.0,
                minSilenceDuration: 1.0,
                rmsThreshold: 0.03
            )
            testVADWithParameters(
                audioSamples: audioSamples,
                name: "Conservative (–¥–ª–∏–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã)",
                parameters: conservative
            )

            print("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            print("üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã VAD\n")

            // 7. Adaptive VAD (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ + ZCR)
            testAdaptiveVAD(
                audioSamples: audioSamples,
                name: "Adaptive VAD - Default",
                parameters: .default
            )

            testAdaptiveVAD(
                audioSamples: audioSamples,
                name: "Adaptive VAD - Low Quality",
                parameters: .lowQuality
            )

            testAdaptiveVAD(
                audioSamples: audioSamples,
                name: "Adaptive VAD - Aggressive",
                parameters: .aggressive
            )

            // 8. Spectral VAD (—á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
            testSpectralVAD(
                audioSamples: audioSamples,
                name: "Spectral VAD - Default",
                parameters: .default
            )

            testSpectralVAD(
                audioSamples: audioSamples,
                name: "Spectral VAD - Telephone",
                parameters: .telephone
            )

            testSpectralVAD(
                audioSamples: audioSamples,
                name: "Spectral VAD - Wideband",
                parameters: .wideband
            )

            print("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            print("   ‚Ä¢ –ï—Å–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Very Sensitive –∏–ª–∏ Aggressive")
            print("   ‚Ä¢ –ï—Å–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Conservative")
            print("   ‚Ä¢ –î–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Low Quality")
            print("   ‚Ä¢ –î–ª—è —á–∏—Å—Ç–æ–≥–æ –∞—É–¥–∏–æ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ High Quality")

        } catch {
            print("‚ùå –û—à–∏–±–∫–∞: \(error.localizedDescription)")
        }
    }

    /// –¢–µ—Å—Ç–∏—Ä—É–µ—Ç VAD —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    static func testVADWithParameters(
        audioSamples: [Float],
        name: String,
        parameters: VADParameters
    ) {
        print("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print("üìä \(name)")
        print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print("   ‚Ä¢ Window Size: \(Int(parameters.windowSize * 1000))ms")
        print("   ‚Ä¢ Min Speech: \(Int(parameters.minSpeechDuration * 1000))ms")
        print("   ‚Ä¢ Min Silence: \(Int(parameters.minSilenceDuration * 1000))ms")
        print("   ‚Ä¢ RMS Threshold: \(String(format: "%.4f", parameters.rmsThreshold))")
        print()

        let vad = VoiceActivityDetector(parameters: parameters)
        let segments = vad.detectSpeechSegments(in: audioSamples)

        print("   –†–µ–∑—É–ª—å—Ç–∞—Ç: \(segments.count) —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        if segments.isEmpty {
            print("   ‚ö†Ô∏è –°–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            print()
            return
        }

        // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
        let totalSpeechDuration = segments.reduce(0.0) { $0 + $1.duration }
        let avgDuration = totalSpeechDuration / Double(segments.count)
        let minDuration = segments.map(\.duration).min() ?? 0
        let maxDuration = segments.map(\.duration).max() ?? 0

        print("   ‚Ä¢ –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–µ—á–∏: \(formatDuration(totalSpeechDuration))")
        print("   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞: \(formatDuration(avgDuration))")
        print("   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: \(formatDuration(minDuration))")
        print("   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: \(formatDuration(maxDuration))")
        print()

        // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–∏–ª–∏ –≤—Å–µ –µ—Å–ª–∏ –º–µ–Ω—å—à–µ)
        let displayCount = min(10, segments.count)
        print("   –ü–µ—Ä–≤—ã–µ \(displayCount) —Å–µ–≥–º–µ–Ω—Ç–æ–≤:")
        for (index, segment) in segments.prefix(displayCount).enumerated() {
            let startTime = formatTime(segment.startTime)
            let endTime = formatTime(segment.endTime)
            let duration = formatDuration(segment.duration)
            print("      \(index + 1). [\(startTime) - \(endTime)] (\(duration))")
        }

        if segments.count > displayCount {
            print("      ... –∏ –µ—â–µ \(segments.count - displayCount) —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        }
        print()
    }

    /// –í—ã–≤–æ–¥–∏—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞—É–¥–∏–æ
    static func printAudioStats(_ samples: [Float]) {
        print("üìà –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ:")

        // RMS (–≥—Ä–æ–º–∫–æ—Å—Ç—å)
        var rms: Float = 0
        vDSP_rmsqv(samples, 1, &rms, vDSP_Length(samples.count))

        // –ü–∏–∫–æ–≤–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞
        var maxValue: Float = 0
        vDSP_maxv(samples, 1, &maxValue, vDSP_Length(samples.count))

        var minValue: Float = 0
        vDSP_minv(samples, 1, &minValue, vDSP_Length(samples.count))

        let peakAmplitude = max(abs(maxValue), abs(minValue))

        // –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω (dB)
        let dynamicRange = 20 * log10(peakAmplitude / (rms + 0.0001))

        print("   ‚Ä¢ RMS (—Å—Ä–µ–¥–Ω—è—è –≥—Ä–æ–º–∫–æ—Å—Ç—å): \(String(format: "%.4f", rms))")
        print("   ‚Ä¢ –ü–∏–∫–æ–≤–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞: \(String(format: "%.4f", peakAmplitude))")
        print("   ‚Ä¢ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω: \(String(format: "%.1f", dynamicRange)) dB")

        // –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ RMS –ø–æ –æ–∫–Ω–∞–º
        print("   ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ RMS –ø–æ –≤—Ä–µ–º–µ–Ω–∏:")
        analyzeRMSDistribution(samples)
    }

    /// –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ RMS –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    static func analyzeRMSDistribution(_ samples: [Float]) {
        let windowSize = 16000 // 1 —Å–µ–∫—É–Ω–¥–∞ –ø—Ä–∏ 16kHz
        var rmsValues: [Float] = []

        var position = 0
        while position + windowSize <= samples.count {
            let window = Array(samples[position..<(position + windowSize)])
            var rms: Float = 0
            vDSP_rmsqv(window, 1, &rms, vDSP_Length(window.count))
            rmsValues.append(rms)
            position += windowSize
        }

        guard !rmsValues.isEmpty else { return }

        // –ù–∞—Ö–æ–¥–∏–º min/max/avg
        let minRMS = rmsValues.min() ?? 0
        let maxRMS = rmsValues.max() ?? 0
        let avgRMS = rmsValues.reduce(0, +) / Float(rmsValues.count)

        print("      Min: \(String(format: "%.4f", minRMS)), " +
              "Avg: \(String(format: "%.4f", avgRMS)), " +
              "Max: \(String(format: "%.4f", maxRMS))")

        // –ü—Ä–æ—Å—Ç–∞—è ASCII –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
        let bucketCount = 5
        var buckets = Array(repeating: 0, count: bucketCount)

        for rms in rmsValues {
            let normalized = (rms - minRMS) / (maxRMS - minRMS + 0.0001)
            let bucketIndex = min(Int(normalized * Float(bucketCount)), bucketCount - 1)
            buckets[bucketIndex] += 1
        }

        print("      –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ (–æ—Ç —Ç–∏—Ö–æ–≥–æ –∫ –≥—Ä–æ–º–∫–æ–º—É):")
        for (index, count) in buckets.enumerated() {
            let bar = String(repeating: "‚ñà", count: count)
            let label = String(format: "%.4f", minRMS + Float(index) * (maxRMS - minRMS) / Float(bucketCount))
            print("      \(label): \(bar) (\(count))")
        }
    }

    /// –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ 16kHz mono Float32
    static func loadAudioFile(_ url: URL) async throws -> (samples: [Float], sampleRate: Double, channelCount: Int, duration: TimeInterval) {
        let asset = AVAsset(url: url)

        guard let audioTrack = try await asset.loadTracks(withMediaType: .audio).first else {
            throw NSError(domain: "VADTest", code: 1, userInfo: [NSLocalizedDescriptionKey: "–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç audio track"])
        }

        let reader = try AVAssetReader(asset: asset)

        // –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π sample rate –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤
        let formatDescriptions = try await audioTrack.load(.formatDescriptions)
        var originalSampleRate: Double = 16000
        var originalChannelCount: Int = 1

        if let formatDescription = formatDescriptions.first,
           let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) {
            originalSampleRate = audioStreamBasicDescription.pointee.mSampleRate
            originalChannelCount = Int(audioStreamBasicDescription.pointee.mChannelsPerFrame)
        }

        // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã–≤–æ–¥–∞: 16kHz, mono, Linear PCM Float32
        let outputSettings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 16000,
            AVNumberOfChannelsKey: 1,
            AVLinearPCMBitDepthKey: 32,
            AVLinearPCMIsFloatKey: true,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsNonInterleaved: false
        ]

        let output = AVAssetReaderTrackOutput(track: audioTrack, outputSettings: outputSettings)
        reader.add(output)

        guard reader.startReading() else {
            throw NSError(domain: "VADTest", code: 2, userInfo: [NSLocalizedDescriptionKey: "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"])
        }

        var audioSamples: [Float] = []

        while let sampleBuffer = output.copyNextSampleBuffer() {
            if let blockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) {
                let length = CMBlockBufferGetDataLength(blockBuffer)
                var data = Data(count: length)

                _ = data.withUnsafeMutableBytes { (bytes: UnsafeMutableRawBufferPointer) in
                    CMBlockBufferCopyDataBytes(blockBuffer, atOffset: 0, dataLength: length, destination: bytes.baseAddress!)
                }

                let floatArray = data.withUnsafeBytes { (ptr: UnsafeRawBufferPointer) -> [Float] in
                    let floatPtr = ptr.bindMemory(to: Float.self)
                    return Array(floatPtr)
                }

                audioSamples.append(contentsOf: floatArray)
            }
        }

        reader.cancelReading()

        let duration = Double(audioSamples.count) / 16000.0

        return (audioSamples, originalSampleRate, originalChannelCount, duration)
    }

    /// –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
    static func formatDuration(_ seconds: TimeInterval) -> String {
        if seconds < 1.0 {
            return String(format: "%.0fms", seconds * 1000)
        } else if seconds < 60.0 {
            return String(format: "%.1fs", seconds)
        } else {
            let minutes = Int(seconds) / 60
            let secs = Int(seconds) % 60
            return String(format: "%dm %ds", minutes, secs)
        }
    }

    /// –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ MM:SS.mmm
    static func formatTime(_ seconds: TimeInterval) -> String {
        let minutes = Int(seconds) / 60
        let secs = Int(seconds) % 60
        let millis = Int((seconds.truncatingRemainder(dividingBy: 1)) * 1000)
        return String(format: "%02d:%02d.%03d", minutes, secs, millis)
    }

    /// –¢–µ—Å—Ç–∏—Ä—É–µ—Ç Adaptive VAD —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    static func testAdaptiveVAD(
        audioSamples: [Float],
        name: String,
        parameters: AdaptiveVAD.Parameters
    ) {
        print("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print("üìä \(name)")
        print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print("   ‚Ä¢ Window Size: \(Int(parameters.windowSize * 1000))ms")
        print("   ‚Ä¢ Min Speech: \(Int(parameters.minSpeechDuration * 1000))ms")
        print("   ‚Ä¢ Min Silence: \(Int(parameters.minSilenceDuration * 1000))ms")
        print("   ‚Ä¢ Threshold Multiplier: \(String(format: "%.2f", parameters.thresholdMultiplier))")
        print("   ‚Ä¢ ZCR Weight: \(String(format: "%.2f", parameters.zcrWeight))")
        print()

        let vad = AdaptiveVAD(parameters: parameters)
        let segments = vad.detectSpeechSegments(in: audioSamples)

        print("   –†–µ–∑—É–ª—å—Ç–∞—Ç: \(segments.count) —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        if segments.isEmpty {
            print("   ‚ö†Ô∏è –°–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            print()
            return
        }

        printSegmentStatistics(segments: segments)
    }

    /// –¢–µ—Å—Ç–∏—Ä—É–µ—Ç Spectral VAD —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    static func testSpectralVAD(
        audioSamples: [Float],
        name: String,
        parameters: SpectralVAD.Parameters
    ) {
        print("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print("üìä \(name)")
        print("   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print("   ‚Ä¢ FFT Size: \(parameters.fftSize)")
        print("   ‚Ä¢ Min Speech: \(Int(parameters.minSpeechDuration * 1000))ms")
        print("   ‚Ä¢ Min Silence: \(Int(parameters.minSilenceDuration * 1000))ms")
        print("   ‚Ä¢ Speech Freq: \(Int(parameters.speechFreqMin))-\(Int(parameters.speechFreqMax)) Hz")
        print("   ‚Ä¢ Energy Ratio: \(String(format: "%.2f", parameters.speechEnergyRatio))")
        print()

        let vad = SpectralVAD(parameters: parameters)
        let segments = vad.detectSpeechSegments(in: audioSamples)

        print("   –†–µ–∑—É–ª—å—Ç–∞—Ç: \(segments.count) —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        if segments.isEmpty {
            print("   ‚ö†Ô∏è –°–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
            print()
            return
        }

        printSegmentStatistics(segments: segments)
    }

    /// –í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º (–æ–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è)
    static func printSegmentStatistics(segments: [SpeechSegment]) {
        let totalSpeechDuration = segments.reduce(0.0) { $0 + $1.duration }
        let avgDuration = totalSpeechDuration / Double(segments.count)
        let minDuration = segments.map(\.duration).min() ?? 0
        let maxDuration = segments.map(\.duration).max() ?? 0

        print("   ‚Ä¢ –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–µ—á–∏: \(formatDuration(totalSpeechDuration))")
        print("   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞: \(formatDuration(avgDuration))")
        print("   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: \(formatDuration(minDuration))")
        print("   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: \(formatDuration(maxDuration))")
        print()

        // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        let displayCount = min(10, segments.count)
        print("   –ü–µ—Ä–≤—ã–µ \(displayCount) —Å–µ–≥–º–µ–Ω—Ç–æ–≤:")
        for (index, segment) in segments.prefix(displayCount).enumerated() {
            let startTime = formatTime(segment.startTime)
            let endTime = formatTime(segment.endTime)
            let duration = formatDuration(segment.duration)
            print("      \(index + 1). [\(startTime) - \(endTime)] (\(duration))")
        }

        if segments.count > displayCount {
            print("      ... –∏ –µ—â–µ \(segments.count - displayCount) —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        }
        print()
    }

    /// –í—ã–≤–æ–¥–∏—Ç —Å–ø—Ä–∞–≤–∫—É –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    static func printUsage() {
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  .build/debug/VADTest <–ø—É—Ç—å_–∫_–∞—É–¥–∏–æ_—Ñ–∞–π–ª—É>")
        print()
        print("–ü—Ä–∏–º–µ—Ä:")
        print("  .build/debug/VADTest /path/to/audio.wav")
        print()
        print("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ VAD –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:")
        print("  ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–µ—á–∏")
        print("  ‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        print("  ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        print("  ‚Ä¢ –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏")
        print()
        print("–ê–ª–≥–æ—Ä–∏—Ç–º—ã:")
        print("  ‚Ä¢ Standard VAD - —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π (RMS)")
        print("  ‚Ä¢ Adaptive VAD - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ + ZCR")
        print("  ‚Ä¢ Spectral VAD - —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (FFT)")
    }
}
