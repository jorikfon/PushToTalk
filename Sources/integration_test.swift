import Foundation
import AVFoundation
import PushToTalkCore

/// –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç: AudioCaptureService + WhisperService
/// –ü–æ–ª–Ω—ã–π pipeline: –º–∏–∫—Ä–æ—Ñ–æ–Ω ‚Üí –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä ‚Üí —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
@main
struct IntegrationTest {
    static func main() async {
        print("=== PushToTalk Integration Test ===")
        print("Testing: AudioCapture ‚Üí Whisper Transcription")
        print("")

        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
        let audioService = AudioCaptureService()
        let whisperService = WhisperService(modelSize: "tiny")

        print("Step 1/5: Checking microphone permissions...")
        let hasPermission = await audioService.checkPermissions()

        guard hasPermission else {
            print("‚ùå Microphone permission denied!")
            print("Please grant microphone access in System Settings > Privacy & Security")
            return
        }

        print("‚úÖ Microphone permission granted")
        print("")

        print("Step 2/5: Loading Whisper model...")
        do {
            try await whisperService.loadModel()
            print("‚úÖ Whisper model loaded successfully")
        } catch {
            print("‚ùå Failed to load Whisper model: \(error)")
            return
        }
        print("")

        print("Step 3/5: Recording audio for 3 seconds...")
        print("üé§ Please speak into your microphone...")
        print("")

        // –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ
        do {
            try audioService.startRecording()
            print("‚è∫Ô∏è  Recording started...")

            // –ó–∞–ø–∏—Å—å 3 —Å–µ–∫—É–Ω–¥—ã
            try await Task.sleep(nanoseconds: 3_000_000_000)

            let audioData = audioService.stopRecording()
            print("‚èπÔ∏è  Recording stopped")
            print("üìä Captured \(audioData.count) samples (\(Double(audioData.count) / 16000.0) seconds)")

            // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª–∞
            let absValues = audioData.map { abs($0) }
            let maxAmplitude = absValues.max() ?? 0
            let sum = absValues.reduce(0, +)
            let avgAmplitude = sum / Float(audioData.count)

            print("   Max amplitude: \(String(format: "%.4f", maxAmplitude))")
            print("   Avg amplitude: \(String(format: "%.4f", avgAmplitude))")

            if maxAmplitude < 0.001 {
                print("‚ö†Ô∏è  Warning: Very low audio signal detected!")
                print("   Please check your microphone input volume")
            }
            print("")

            print("Step 4/5: Transcribing audio with Whisper...")
            let startTime = Date()

            let transcription = try await whisperService.transcribe(audioSamples: audioData)

            let elapsed = Date().timeIntervalSince(startTime)
            print("‚úÖ Transcription completed in \(String(format: "%.2f", elapsed)) seconds")
            print("")

            print("Step 5/5: Results")
            print("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            if transcription.isEmpty {
                print("‚ö†Ô∏è  No speech detected or empty result")
                print("Possible reasons:")
                print("  - No speech in the recording")
                print("  - Audio level too low")
                print("  - Background noise only")
            } else {
                print("üìù Transcription: \"\(transcription)\"")
                print("")
                print("‚úÖ SUCCESS! Full pipeline working correctly")
            }
            print("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")

        } catch {
            print("‚ùå Error during recording or transcription: \(error)")
            return
        }

        print("")
        print("=== Test Completed ===")
    }
}
